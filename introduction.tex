\section{Introduction}
With the increasing of sensor performance and the rapid expansion of social network data, it is necessary to parallelize or distribute the analysis and computation of large scale data. However, the parallelization of algorithms requires programmers to have a rich knowledge of distributed systems. A large number of big data analysis systems have been proposed which provide high-level language for expressing the computation logic \cite{}. Even so, these systems still require the users to understand the specific programming logic. For example, the typical representative of the BSP computing model, Pregel \cite{} adopts a vertex-centric programming model. It requires programmers to write vertex-centric programs and Explicitly manage the communication.

New interest has recently re-emerged around Datalog for a wide spectrum of knowledge-oriented applications \cite{}%Bigdatalog 25,27,64,47,49}.

Datalog is an excellent candidate language for large-scale data analytics because of its high-level declarative semantics and support for recursion. Datalog's support for recursion makes the expression of data analysis natural \cite{} and its high-level semantics makes it amenable to parallelization and optimization \cite{}.


In recent years, many system research efforts have raised to improve the performance and scalability of Datalog systems. Socialite \cite{socialite} provides a large scale graph evaluation system supporting both sequential and distribute environment. In Socialite, users can define recursive aggregate functions which, as long as they are meet operations, can be evaluated incrementally and efficiently. The \textit{7113340} project provides a full Datalog language implementation and seeks to provide  system supports that optimizes execution over diverse platforms including sequential implementations \cite{Shkapsky:2016:BDA:2882903.2915229}, multi-core machines [59], and clusters \cite{bigdatalog}. It supports relational algebra, aggregation, and recursion, as well as a host of declarative optimizations. MyriaX \cite{Halperin:2014:DMB:2588555.2594530} implements a Datalog System on share-nothing engines based on Myria \cite{}. The computations are incremental, and it support s a variety of iterative models (synchronous, asynchronous, different processing priorities) and failure-handling techniques. It is worth mentioning that MyriaX supports asynchronous processing and shows promising performance for some applications, but it fails to tell in which cases asynchronous processing is suited.

Compared with synchronous recursive processing, asynchronous recursive processing has many advantages, such as fast convergence \cite{}, more efficient resource utilization \cite{}, and priority scheduling \cite{}. However, in practical usage, synchronous systems are more popular than asynchronous systems, which can be attributed to the following three points:

Compared with synchronous recursive processing, asynchronous recursive processing has many advantages, such as fast convergence \cite{}, more efficient resource utilization \cite{}, and priority scheduling \cite{}. However, in practical usage, synchronous systems are more popular than asynchronous systems, which can be attributed to the following three points:

First, \textbf{Non-guaranteed Correctness}. There are several prior works that have employed asynchronous processing engine for improving their system performance. However, these systems only implement asynchronous execution of parallel/distributed algorithms, without any correctness guarantee of the results \cite{}. Asynchronous computation model are blindly used and may result in inconsistent results for convex functions. Maiter \cite{} provides the sufficient conditions for correct asynchronous computations, but these conditions are only suitable in the context of vertex-centric graph computations.

Second, \textbf{More Complexity}. Programmers are used to write sequential programs or synchronous parallel programs. Had the asynchronization conditions been formally given, it is still hard for a non-expert programmer to manually verify these conditions from their programs. In addition, writing asynchronous programs and designing asynchronous systems are even harder, because asynchronous implies disorganized and as a result complicated. Experience from Google \cite{} strongly suggests a synchronous programming model, since asynchronous code is a lot harder to write, tune, and debug.

Third, \textbf{Unstable Performance}. Asynchronous iterative processing avoids the intermediate result coordination phase. The parallel executions of operations are not synchronized and not strictly ordered. This implies that the computations and communications are not under control any more, which may lead to stale computations/communications and potentially reduces the efficiency. The performance gain from asynchronous computation may be not enough to compensate for the performance loss from stale computations/commmunications, leading to unstable performance.


In order to solve these problems, we design and implement a Datalog system supporting automated asynchronous execution, A3Log. Our system is able to automatically check whether a recursive Datalog program can return correct result with asynchronous recursive execution. This is achieved by automated sufficient conditions verification. Maiter \cite{} provides the sufficient conditions for asynchronous graph processing. In this paper, we generalize the sufficient conditions through the analysis of aggregate and non-aggregate operators, which can be easily identified from a user's Datalog program. Aggregate operation is known to be hardly parallelized \cite{distribute aggregate from ms}, while non-aggregate operation can be embarrassingly parallel. Synchronization of parallel computations seems to be the unavoidable coordination step for correct aggregation result though it is known costly. Our new sufficient conditions are provided by analyzing the properties of aggregate operations and non-aggregate operations. A3Log can also automate the condition verification process without user's participation. Further, A3Log provides both shared-memory runtime engine and distributed runtime engine for fast execution.

The contributions of this paper are summarized as follows.
\begin{itemize}
	\item To guarantee the correctness of recursive Datalog program, we clearly define the sufficient conditions that guarantee asynchronous processing to return the same result as synchronous processing through the analysis of aggregate and non-aggregate operators. Even for some recursive programs that do not satisfy these conditions, we propose an approach to conditionally convert them to be qualified for asynchronous aggregation.
	\item To alleviate the burden of programmers, we propose an automated condition verification technique by leveraging satisfiability modulo theories
	(SMT) . User?s sequential program can be automatically checked for asynchronization possibilities and can even be automatically converted to the asynchronous program.
	\item We propose a Datalog implementation, A3Log, to support automated asynchronous aggregation. A3Log is built by modifying distributed Socialite \cite{}. The condition verification techniques are embedded in a Condition Checker component, so that it can asynchronize user's program automatically. A3Log provides both shared-memory runtime engine and distributed runtime engine. The evaluation of a Datalog program are mapped to the update of a distributed hash table structure. By various optimizations, such as concurrency control, priority scheduling, and termination control, users' Datalog programs can be efficiently executed on our system.
	\item We experimentally evaluate A3Log, compared with Socialite [30, 39], GraphLab [33], Myria[49] and Maiter [55].We also perform evaluations with 7 algorithms on 20 more datasets. The experiments are performed on a 32-core instance for many-core experiments and on a cluster with 64 instances for distributed experiments. Our results show that A3Log outperforms other systems in many-core experiments and shows comparable performance with Maiter in distributed experiments. Our results also show that the asynchronous execution of A3Log can achieve 2.25X-222.82X speedup over the synchronous version for various datasets.
\end{itemize}

The rest of the paper are organized as follow: In Sec.2 we describe the details of  automatic asynchronous technology. In Sec.3 we propose a datalog system based on automatic asynchronous the technology .In Section.4  we give the performance evaluation. And then we review the related works in Sec 5 and then conclude the paper in Sec.7
