\section{Introduction}
With the increasing of sensor performance and the rapid expansion of social network data, it is necessary to parallelize or distribute the iterative computation of large scale data. However, the parallelization of algorithms requires programmers to have a rich knowledge of distributed systems. A large number of big data analysis systems have been proposed which provide high-level language for expressing the recursive computation logic \cite{Dean:2004:MSD:1251254.1251264,giraph,maiter,Fan:2017:PSG:3035918.3035942,Malewicz2010Pregel,DBLP:journals/corr/GonzalezBJFHGS15,8017445,Low:2012:DGF:2212351.2212354,Han:2015:GUB:2777598.2777604,grace}. Even so, these systems still require the users to understand the specific programming logic. For example, the typical representative of the BSP computing model, Pregel \cite{Malewicz2010Pregel} adopts a vertex-centric programming model. It requires programmers to write vertex-centric programs and Explicitly manage the communication.
\begin{comment}
{\color{red}
New interest has recently re-emerged around Datalog for a wide spectrum of knowledge-oriented applications \cite{Aref:2015:DIL:2723372.2742796,7840589,Shkapsky:2013:GQN:2536274.2536290,Alvaro:2010:DDT:2185923.2185942,Shkapsky:2016:BDA:2882903.2915229,Lam:2013:SDE:2510649.2511289,Seo:2013:DSD:2556549.2556572,Wang:2015:AFR:2824032.2824052}%Bigdatalog 25,27,64,47,49}.\begin{comment}
{\color{red}Datalog is an excellent candidate language for large-scale data analytics because of its high-level declarative semantics and support for recursion. Datalog's support for recursion makes the expression of data analysis natural \cite{}{\color{red}which paper}  and its high-level semantics makes it amenable to parallelization and optimization \cite{}{\color{red}which paper}.

In recent years, many system research efforts have raised to improve performance  and scalability based on Datalog systems. Socialite \cite{Lam:2013:SDE:2510649.2511289,Seo:2013:DSD:2556549.2556572} provides a large scale graph evaluation system supporting both sequential and distribute environment. In Socialite, users can define recursive aggregate functions which, as long as they are meet operations, can be evaluated incrementally and efficiently. The \cite{7113340} project provides a full Datalog language implementation and seeks to provide  system supports that optimizes execution over diverse platforms including sequential implementations \cite{Shkapsky:2016:BDA:2882903.2915229}, multi-core machines, and clusters \cite{Shkapsky:2016:BDA:2882903.2915229}. It supports relational algebra, aggregation, and recursion, as well as a host of declarative optimizations. MyriaX \cite{Halperin:2014:DMB:2588555.2594530} implements a Datalog System on share-nothing engines based on Myria \cite{Halperin:2014:DMB:2588555.2594530}. The computations are incremental, and it support s a variety of iterative models (synchronous, asynchronous, different processing priorities) and failure-handling techniques. It is worth mentioning that MyriaX supports asynchronous processing and shows promising performance for some applications, but it fails to tell in which cases asynchronous processing is suited.
}
\end{comment}
There are two basic execution strategy,asynchronous and synchronous execution.Compared with synchronous recursive processing, asynchronous recursive processing has many advantages, such as fast convergence \cite{maiter}, more efficient resource utilization \cite{}{\color{red}which paper} , and priority scheduling \cite{Zhang:2011:PDF:2038916.2038929}. Note that Asynchronous is not always the better choice.When asynchronously executed, some algorithm might shows comparable performance with synchronous execution.or even worst. But this issue does not affect asynchronous as an excellent execution strategy.However, in practical usage, synchronous systems are more popular than asynchronous systems, which can be attributed to the following points:


First, \textbf{Non-guaranteed Correctness}. There are several prior works that have employed asynchronous processing engine for improving their system performance. However, these systems only implement asynchronous execution of parallel/distributed algorithms, without any correctness guarantee of the results \cite{Low:2012:DGF:2212351.2212354}. Asynchronous computation model are blindly used and may result in inconsistent results for convex functions. Maiter \cite{maiter} provides the sufficient conditions for correct asynchronous computations, but these conditions are only suitable in the context of vertex-centric graph computations,and programmer should judge the conditions manually and rewrite the program.

Second,\textbf{Ununified computing expression}.
Recursive Algorithm usually has ununified computing expression.Even if the correctness condition are given,it is still difficult to check it from variety handwrite program with different style. Not to say convert the normal program into asynchronous formulation.It seems that we need an high-declarative language to express the computing logic.
%Third, \textbf{More Complexity}. Programmers are used to write sequential programs or synchronous parallel programs. Had the asynchronization conditions been formally given, it is still hard for a non-expert programmer to manually verify these conditions from their programs. Not to say convert the normal program into asynchronous formulation.In addition, writing asynchronous programs and designing asynchronous systems are even harder, because asynchronous implies disorganized and as a result complicated. Experience from Google \cite{}{\color{red}which paper} strongly suggests a synchronous programming model, since asynchronous code is a lot harder to write, tune, and debug.
Third, \textbf{More Complexity}. Programmers are used to write sequential programs or synchronous parallel programs. So writing asynchronous programs and designing asynchronous systems are even harder, because asynchronous implies disorganized and as a result complicated. Experience from Google \cite{}{\color{red}which paper} strongly suggests a synchronous programming model, since asynchronous code is a lot harder to write, tune, and debug.

%{\color{red}
%Third, \textbf{Unstable Performance}. Asynchronous iterative processing avoids the intermediate result coordination phase. The parallel executions of operations are not synchronized and not strictly ordered. This implies that the computations and communications are not under control any more, which may lead to stale computations/communications and potentially reduces the efficiency. The performance gain from asynchronous computation may be not enough to compensate for the performance loss from stale computations/commmunications, leading to unstable performance.
%}



In an iterative computation can be abstracted into a series of non-aggregate and aggregate operations.Aggregate operation is known to be hardly parallelized{\color{red}which paper} \cite{distribute aggregate from ms}, while non-aggregate operation can be embarrassingly parallel.
First,we abstract the iterative computation into recursive aggregation program. And then we  Then we proposed accumulate recursive aggregation and defined the conversion conditions from normal recursive aggregations. Then we generalized the correctness conditions based on the analysis of aggregate and non-aggregate operations.Further some unsatisfiable algorithm, can even be automatically converted to the asynchronous program with our convertible schema.
we also design and implement a Datalog system supporting automated asynchronous execution, A3Log.We choose Dalalog as its high level language because of its high-level declarative semantics and support for parallel recursion{\color{which paper}}\cite{}. Our system is able to automatically check whether a recursive Datalog program can return correct result with asynchronous recursive execution from user's Datalog program. This is achieved by automated sufficient conditions verification using Z3 smt solver. 
 A3Log can also automate the conversion for some algorithm that satisfied the convertible condition without user's participation. Further, A3Log provides both shared-memory runtime engine and distributed runtime engine for fast execution.

%Maiter \cite{maiter} provides the sufficient conditions for asynchronous graph processing,but these conditions are not generalized enough and only suit for several graph algorithm. In this paper, we generalize the sufficient conditions which can be easily identified from  user's Datalog program. %Aggregate operation is known to be hardly parallelized \cite{distribute aggregate from ms}, while non-aggregate operation can be embarrassingly parallel.% Synchronization of parallel computations seems to be the unavoidable coordination step for correct aggregation result though it is known costly. 
The contributions of this paper are summarized as follows.
\begin{itemize}
	%{\color{red}\item To guarantee the correctness of recursive Datalog program, we proposed a series of conditions of converting  recursive aggregation into a self-defined \textbf{Accumulative Recursive AgGregation}. Moreover new sufficient conditions that guarantee asynchronous processing to return the same result as synchronous processing. which has proposed based on the analysis  of aggregate and non-aggregate operators in ARAG.Even for some recursive programs that do not satisfy these conditions, we propose an approach to conditionally convert them to be qualified for asynchronous aggregation.}
	\item We define a new aggregation calculation model named accumulative recursive aggregation.And,proposed convert conditions for normal recursive aggregation.further we give the conditions for correctly asynchronous execute accumulative recursive aggregations based on the analysis of aggregate and non-aggregate operations.  
	\item To alleviate the burden of programmers, we propose an automated condition verification technique by leveraging satisfiability modulo theories(SMT). User's sequential program can be automatically checked for asynchronous possibilities and can even be automatically converted to the asynchronous program.
	\item We propose a Datalog implementation, A3Log, to support automated asynchronous aggregation. A3Log is built by modifying distributed Socialite \cite{Seo:2013:DSD:2556549.2556572}. The condition verification techniques are embedded in a Condition Checker component, so that it can asynchronize user's program automatically.	 A3Log provides both shared-memory runtime engine and distributed runtime engine. The evaluation of a Datalog program are mapped to the update of a distributed Hash table structure. By various optimizations, such as concurrency control, priority scheduling, and termination control, users' Datalog programs can be efficiently executed on our system.
%	\item We experimentally evaluate A3Log, compared with Socialite [30, 39], GraphLab [33], Myria[49] and Maiter [55].We also perform evaluations with 7 algorithms on 20 more datasets. The experiments are performed on a 32-core instance for many-core experiments and on a cluster with 64 instances for distributed experiments. Our results show that A3Log outperforms other systems in many-core experiments and shows comparable performance with Maiter in distributed experiments. Our results also show that the asynchronous execution of A3Log can achieve 2.25X-222.82X speedup over the synchronous version for various datasets.
\end{itemize}

The rest of the paper are organized as follow: In Sec.2 we describe the details of  automatic asynchronous technology. In Sec.3 we propose a datalog system based on automatic asynchronous the technology .In Section.4  we give the performance evaluation. And then we review the related works in Sec 5 and then conclude the paper in Sec.7
