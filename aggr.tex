\section{Revisit Aggregate Operation}
\label{sec:aggre}

A \emph{sequential} computation (as opposed to parallel/distributed computation) is composed of a sequence of operations on input. These operations can be classified into two categories, the aggregate operations and the non-aggregate operations.  We focus on numerical aggregation in this paper.
 \subsection{Aggregate/Non-Aggregate Operations}
An \emph{\textbf{aggregate operation}} is a function $g()$ that requires more than one variables as input, i.e., $g(Y)$ where $Y=\{y_1, y_2, \ldots, y_n\}$, and outputs one value. For example, MAX, MIN, SUM, AVG, and COUNT are commonly used aggregate operations.A special but common case is the \emph{\textbf{group-by aggregation}}. A set of input key-value pairs are grouped by key, and the values in each group are aggregated to obtain a new set of key-value pairs. In other words, the group-by aggregation is composed of multiple subset aggregate operations.
To apply the aggregate operation on the whole dataset. We define group-by aggregation $G_k$ of $g$ as follow: 
\begin{definition}
	\begin{align}
		 Y&=\{Y_{k_0} \cup Y_{k_1} \cup ... \cup Y_{k_n}\}\notag\\	 
	 G_k(Y)&=\{g(Y_{k_0}) \cup g(Y_{k_1}) \cup \dots \cup g(Y_{k_n})\} \notag
 \end{align}
\end{definition}

The input is a vector output by non-aggregate operations denotes as $Y$. in which $Y_{k_i}$is the subset of $Y$ belongs to $k_i$.The output is a vector,the $i$th item is the aggregate result of key $k_i$.Note that there is no intersection between different subset,i.e.$Y_i \cup Y_j = \emptyset $
 
On the contrary, a \emph{\textbf{non-aggregate operation}} is a function that takes only one value as input, i.e., $f(x)$, and outputs zero or more values. Since non-aggregate operation only takes one value unit as input,Here we gives a new operation $F_k(X)$ which apply $f$ on the whole set by their keys.
\begin{definition}
	\begin{align}
	X&=\{x_{k_0}, x_{k_1}, ... x_{k_n}\}\notag\\	 
	F_k(X)&=\{f(x_{k_0}) \cup f(x_{k_1}) \cup \dots \cup f(x_{k_n})\} \notag
	\end{align}
\end{definition}
Input $X$ is a vector of  initial values or the aggregate results.outputs is vector which constructed by all the non-aggregate results. 
 It is obvious that $F_k(X)$ has a distributivity property upon $\cup$ operator, i.e.$F_k(X \cup Y)=F_k(X) \cup F_k(Y)$.
In essence, the aggregate operation implies a \emph{data fusion}, while a non-aggregate operation implies a \emph{data transformation}.

%Note that, the aggregate and non-aggregate operation should be judged according to the number of \emph{variable} inputs instead of constant inputs. For example, the join operation in relational algebra is in general an aggregation since it merges two data sets into one. It takes two inputs $A$ and $B$ and produces one output. However in distributed join implementation, the whole data set  $B$ can be small enough to be cached on all distributed workers, which implies that $B$ is a constant input for the distributed join operations. By partitioning and distributing $A$, the join operation is achieved by merging a part of $A$ and the locally cached whole $B$ on each worker. In such a case, the join operation is considered as a non-aggregate operation because each distributed join operation only takes a part of $A$ as a variable input which is different on different processor, where $B$ is the constant for all processors.

\textbf{Parallelization}:Non-aggregate operation $f()$ only takes one input and does not rely on any other variable, which makes the $F_k$ operations have the distributive property. By partitioning and distributing the inputs to many workers, the non-aggregate operations can be embarrassingly parallel \emph{without communication} between workers. The aggregate operation $g()$ takes many value as input which may originate from other workers, so that these aggregate operations and the group-by aggregation $G_k()$ can be parallelized but \emph{with communication} between workers. If the inputs for all aggregate operations comes from same work, these aggregate operations can be parallelized without communication by carefully partitioning the inputs. However, this is usually impossible since the inputs probably result from the previous computations on other workers and cannot be particularly partitioned.In other words,the non-aggregate operations can be executed without waiting for all the inputs prepared, but the aggregate operations has to wait for all the inputs prepared when synchronously executed,which incur a lot of coordination costs.


\subsection{Recursive Aggregation}


\emph{Recursive aggregation} is a sequence of interleaving aggregate and non-aggregate operations where all the aggregate operations are the same and all the non-aggregate operations are the same\footnote{There are also recursive programs without aggregations, which can be embarrassingly parallel.}. It is very common in graph algorithms, data mining and machine learning algorithms. The program with recursive aggregation is referred to as \emph{recursive program}. In this paper, we will focus on optimizing the computations with recursive aggregation.

Let $Y$ denote a set of input variables of aggregate operation $\{Y_{k_0},Y_{k_1},\dots,Y_{k_m}\}$and $X$ denote the inputs of non-aggregate  operation.$\{x_{k_0},x_{k_1},\dots,x_{k_n}\}$%Define $F(X)$ as $\{f(x_0^k) \cup f(x_1^k) \cup \dots \cup f(x_n^k)\}$ that is performing non-aggregation function $f(\dot)$for each item in the set and then combine them. Similarly, We define $G(Y)$as $\{g(Y_0) \cup g(Y_1) \cup \dots \cup g(Y_n)\}$ in which $X_i$ is a subset of inputs X,note that there may be an intersection between any two subsets.
Then a recursive program can be represented as follow.
\begin{equation}
\label{eq:recursive2}
\begin{aligned}
Y^{k}=F_k(X^k),\\
X^{k+1}=G_k(Y^k)
\end{aligned}
\end{equation}
It  start from $X^0$ in which case the update order is exchanged and an aggregation is first applied. This recursive program terminates when there is no difference between $X^{k+1}$ and $X^k$ or the difference between $X^{k+1}$ and $X^k$ is small enough. Let $(G_k\circ F_k)^n$ denote $n$ applications of $(G_k\circ F_k)$. The final result of the recursive program is $(G_k\circ F_k)^n(X^0)$. Since $X$ contains a set of data items, the $F_k()$ operation can be parallelized with each working on a subset of $X$. The aggregate operation $G_k()$ can be parallelized  but has to synchronized to wait for the complete set of $Y^{k}$.Note that simplify $G_k()$ as $G()$ and $F_k()$ as $F()$ in the later text if there is no other statement.

\textbf{Example 1: Compuiting Paths in a DAG} This algorithm (denoted as \textbf{PATHS})counts the paths between all the pairs of vertices in an acyclic graph. the Path number $path(s,d)$ is initialized as $1$ for each edge$\langle s,d\rangle$ and $0$ for others. the $f$ operations of $k$th recursion for vertice pair $\langle s,d\rangle$ take the $path^k\langle s,d\rangle$ as input. And then output $path_{tmp}^k\langle s,d'\rangle$ if edge $\langle d,d'\rangle$ exist. the aggregation operation $g()$ operations with respect to each pair $\langle s,d'\rangle$ take all the $path_{tmp}^k\langle s,d'\rangle$ as input and performs $path^{k+1}\langle s,d'\rangle=\sum_d path_{tmp}^k\langle s,d'\rangle+path^k\langle s,d'\rangle$ as the result. Computation terminates when all the path are not changed from previous recursion.

\textbf{Example 2: SSSP} The single source shortest path (SSSP) computation is a recursive program that derives the shortest distance from a source node to all other nodes in a graph. The shortest distance is initialized as $+\infty$ for each node except for the source, which is initialized as 0. The $f()$ operation for a node $i$ takes a tuple $\langle i,d_i^k\rangle$ as input where $d_i^k$ is the shortest distance in the $k$th recursion, computes $f(d_i^k)=d_i^k+w_{i,j}=td_j^{k+1}$ for any outgoing neighbors $j$ (where $w_{i,j}$ is the distance from node $i$ to $j$), and outputs the tuples set $\{\langle j,td_j^{k+1}\rangle\}$ and its own $\langle i,d_i^k\rangle$. The aggregate operation $g()$ with respect to each node $j$ takes the input tuples $\{\langle j,td_j^{k+1}\rangle\}$, performs aggregation $g(td_j^{k+1})=min(\{td_j^{k+1}\},d_j^k)=d_j^{k+1}$, and outputs $\langle j,d_j^{k+1}\rangle$. It terminates when all nodes' shortest distances are not changed from previous recursion.

%\textbf{Example 2: PageRank} The PageRank computation is another typical recursive program for ranking the nodes in a graph. The ranking score is initialized as $r_i^0=1/|V|$ for each node $i$ where $|V|$ is the total number of nodes. The $f()$ operation for node $i$ takes a tuple $\langle i,r_i^k\rangle$ as input where $r_i^k$ is the ranking score in the $k$th recursion, computes $f(r_i^k)=0.85*r_i^k/d_i=tr_j^{k+1}$ for any outgoing neighbors $j$ (where 0.85 is the constant damping factor and $d_i$ is the out-degree of node $i$), and outputs the tuples set $\{\langle j,tr_j^{k+1}\rangle\}$. The aggregate operation $g()$ with respect to each node $j$ takes the input tuples $\{\langle j,tr_j^{k+1}\rangle\}$, performs aggregation $g(\{tr_j^{k+1}\})=\sum_j{tr_j^{k+1}}+0.15=r_j^{k+1}$ and outputs $\langle j,r_j^{k+1}\rangle$. It terminates when the difference between two continuous recursions' ranking scores is small enough.
